# Scraper Service

The Scraper Service is responsible for collecting real estate advertisements from various websites and transforming the unstructured data into a structured format for further processing. This service leverages the **Parsehub API**, enabling efficient and flexible web scraping through a highly customizable configuration. The scraped data is then prepared and injected into a messaging queue for subsequent handling by other components in the system.

## Key Features

- **Web Scraping:** Extracts real estate advertisements from target websites using the Parsehub scraping tool. 
- **Configuration by Business Users:** Business users can configure the scraper to adapt to new website structures or additional scraping requirements.
- **API Integration:** Utilizes the Parsehub API to control scraping jobs, fetch results, and manage workflows programmatically.
- **Data Injection:** Once data is collected and processed, it is published to an **ActiveMQ** messaging queue for further processing by downstream services.

## Components

### 1. Scraper Initialization
- Starts a scraping job on Parsehub using its API.
- Allows users to monitor the status of ongoing scraping jobs.

### 2. Data Collection
- Downloads the structured data (e.g., JSON format) generated by Parsehub after a scraping job completes.

### 3. Queue Integration
- Injects the scraped data into an **ActiveMQ** queue, ensuring seamless communication between services and efficient pipeline processing.

## Benefits

- **Scalability:** The service supports adding new target websites for scraping as business requirements evolve.
- **Automation:** Automates data extraction and delivery, reducing manual overhead.
- **Robust Integration:** Ensures data continuity and real-time updates via the messaging queue.

## Configuration

- **Parsehub Project Setup:** Users must create and configure Parsehub projects for each target website. 
- **API Keys:** The service requires a valid Parsehub API key to authenticate and interact with the Parsehub API.
- **Queue Settings:** Configurable settings for ActiveMQ are included to facilitate seamless integration with other services.

## Technologies Used

- **Java:** For building the backend application.
- **Spring Boot:** To implement the application logic and manage API interactions.
- **ActiveMQ:** For messaging and communication with other services.
- **Parsehub API:** For executing and managing scraping tasks.

## How It Works

1. The user initiates a scraping job via the service.
2. Parsehub scrapes the data based on the preconfigured project settings.
3. Once the scraping job completes, the service fetches the results using the Parsehub API.
4. The collected data is validated, transformed (if needed), and injected into the ActiveMQ queue.


## Prerequisites

- Java 8 or higher
- Maven
- ActiveMQ

## Setup

1. **Clone the repository**:
   \```sh
   git clone <repository-url>
   cd <repository-directory>
   \```

2. **Configure ActiveMQ**:
   Ensure ActiveMQ is running and accessible.

3. **Update `application.properties`**:
   Configure the necessary properties in `src/main/resources/application.properties`:
   \```properties
   spring.activemq.broker-url=tcp://localhost:61616
   spring.activemq.user=admin
   spring.activemq.password=admin
   spring.activemq.packages.trust-all=true
   server.port=8083
   api.key=tH_JPiY0Y3fL
   project.token=tHHkvRCiudLU
   base.url=https://www.parsehub.com/api/v2
   jms.queue.name=AdsQueue
   \```

## Build and Run

1. **Build the project**:
   \```sh
   mvn clean install
   \```

2. **Run the application**:
   \```sh
   mvn spring-boot:run
   \```

## Usage

### Fetch and Process Data

The `Scraper` class fetches data from an external API using an HTTP GET request. The fetched data is processed in the `SpringBootActiveMqDemoApplication` class.

### Publish Messages

The `PublishController` provides endpoints to publish messages to the ActiveMQ queue.

- **Endpoint**: `/api/publish`
- **Method**: POST
- **Parameters**:
  - `message` (required): The message to be published.
  - `queueName` (optional): The name of the queue.

Example:
\```sh
curl -X POST "http://localhost:8083/api/publish?message=TestMessage"
\```

- **Endpoint**: `/api/publish/ad`
- **Method**: POST
- **Parameters**:
  - `ad` (required): The Ad object to be published.
  - `queueName` (optional): The name of the queue.

Example:
\```sh
curl -X POST -H "Content-Type: application/json" -d '{"name":"Example Ad","code_zimmo":"12345"}' "http://localhost:8083/api/publish/ad"
\```

## Project Structure

- `src/main/java/com/bridgingcode/springbootactivemqdemo`:
  - `SpringBootActiveMqDemoApplication.java`: Main application class.
  - `Scraper.java`: Class to fetch data from an external API.
  - `model/Ad.java`: Model class for Ad objects.
  - `publisher/controller/PublishController.java`: Controller to publish messages to ActiveMQ.

## Future Enhancements

- Add support for additional scraping tools.
- Enhance error handling and logging mechanisms.
- Provide a user-friendly dashboard for managing scraping configurations.

## License

This project is licensed under the MIT License. See the `LICENSE` file for details.